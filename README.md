# ABOUTME: Introduces the twin-engine learning analytics project and how to run it.
# ABOUTME: Documents setup, directory layout, and placeholder commands for the workflows.

# deepKT + Wide&Deep IRT Skeleton

This repository scaffolds two complementary analytics engines:

1. **Student readiness** via Sequential Attention Knowledge Tracing (SAKT) implemented with pyKT.
2. **Item health** via the Wide & Deep IRT architecture that fuses clickstream behavior with psychometrics.

Both engines will eventually consume the same canonical learning-event schema so their outputs can be joined inside reports or demos. This skeleton focuses on reproducibility, deterministic data splits, and clear extension points before any modeling code is written.

## Quickstart

1. Create the environment (uv recommended):

   ```
   uv venv
   source .venv/bin/activate
   uv pip install -r requirements.txt
   ```

   Conda users can still rely on `environment.yml`.

2. Inspect available commands:

   ```
   make help
   ```

3. Run the workflows end-to-end:

   ```
   make data split_seed=42
   make data dataset=assistments_skill_builder split_seed=42
   make train_wdirt config=configs/wd_irt_edm.yaml
   make train_sakt config=configs/sakt_assist2009.yaml
   make export
   make demo student_id=123 topic=fractions time_window=2023-W15
   ```

`make data` now materializes canonical learning events and deterministic splits (use `dataset=assistments_skill_builder` to process the ASSISTments file). The other targets currently echo the commands they will run once training/evaluation code lands.

## Directory Layout

```
.
├── configs/           # YAML configs for WD-IRT and SAKT runs
├── data/              # Raw/interim/processed splits plus download scripts
├── execplans/         # ExecPlan documents maintained per PLANS.md
├── reports/           # Auto-generated metrics, plots, behavior summaries
├── scripts/           # CLI entry points (demo, utilities)
└── src/
    ├── common/        # Shared schemas, feature utilities, evaluation helpers
    ├── sakt_kt/       # pyKT training adapters and exporters
    └── wd_irt/        # Clickstream feature builders and Wide&Deep models
```

Key artifacts described in `plan.md` include:

- `item_params.parquet`, `item_drift.parquet`, `behavior_slices.md` generated by Wide & Deep IRT.
- `student_state.parquet`, `next_correct_predictions.parquet` produced by SAKT.
- Joined demo outputs surfaced through `scripts/demo_trace.py`.

## Data Protocol

- **Raw data** (`data/raw/`): immutable downloads such as EDM Cup 2023 clickstream and ASSISTments2009 sequences. Store metadata or checksum files instead of the datasets themselves.
- **Interim data** (`data/interim/`): canonical learning-event tables created by deterministic preprocessing scripts. Each file name encodes `dataset`, `split`, and `seed`.
- **Processed data** (`data/processed/`): model-ready features aligned with config names.
- The split policy is fixed per dataset: create `train`, `val`, and `test` splits by user ID and persist the split manifest under `data/splits/<dataset>_<seed>.json`.

Document any new dataset or transformation inside `data/README.md` before committing the files.

## Configuration

Two starter configs live under `configs/`:

- `wd_irt_edm.yaml` describes the EDM Cup pipeline (feature groups, clickstream windows, optimizer settings, export paths).
- `sakt_assist2009.yaml` configures pyKT’s SAKT baseline (dataset pointer, embedding size, attention heads, dropout, trainer parameters).

Add new configs instead of editing these defaults so experiment history remains reproducible.

## Demo CLI

`scripts/demo_trace.py` exposes a Typer-based CLI. Once the models are trained, running

```
python scripts/demo_trace.py --student-id 123 --topic fractions --time-window 2023-W15
```

will combine SAKT mastery signals with WD-IRT item health summaries for the requested student/topic/time window. For now the command prints a structured TODO message describing the expected inputs/outputs.

## Next Steps

1. Implement the Wide & Deep IRT pipeline under `src/wd_irt/`, starting with clickstream feature builders.
2. Integrate pyKT’s SAKT model using the adapters defined in `src/sakt_kt/`.
3. Unify both pipelines on the shared schema in `src/common/schemas.py`.
4. Replace placeholder Makefile commands with actual training/evaluation/export invocations.
